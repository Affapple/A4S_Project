{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e97372",
   "metadata": {},
   "source": [
    "# Test dataset\n",
    "In this file, we aim to get 4 sets of examples to test our metric:\n",
    "- Well-classified examples\n",
    "- Wrongly classified examples\n",
    "- Adversarial examples (well classified examples modified to be wrongly classified)\n",
    "- Original examples of the adversarial examples before attack\n",
    "\n",
    "By running this file you should get a file called `metric_testing_dataset.pkl`, which is a pickle file of a dictionary `dict[str, np.ndarray]`, with the examples to be used to test the metric.\\\n",
    "This file should be copied into `./tests/data/metric_testing_dataset.pkl` to be used for testing in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffee44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of examples to save for each set\n",
    "NUM_EXAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f966735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/jgaspar/7CCE3FA7CE3F589A1/MCS/1_Semester/ai/mnist/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from art.attacks.evasion import ProjectedGradientDescent, FastGradientMethod\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import Model, get_mnist_dataset, load_cnn_model\n",
    "\n",
    "def exit():\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            return []\n",
    "    raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c786066",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") # Keep CPU to not deal with space constraints\n",
    "\n",
    "model: Model = load_cnn_model()\n",
    "if model is None:\n",
    "    print(\"Could not load model, something went wrong\")\n",
    "    exit()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, test_dataset = get_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad081581",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=len(test_dataset),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c716b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2120c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 98.95% (9895/10000)\n"
     ]
    }
   ],
   "source": [
    "# Classify test dataset\n",
    "pred = model.forward(X_test)\n",
    "pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "well_classified = y_test[pred == y_test]\n",
    "\n",
    "accuracy = (pred == y_test).sum().item() / len(y_test)\n",
    "print(f\"Accuracy on test dataset: {accuracy*100:.2f}% ({len(well_classified)}/{len(y_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa0f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model, \n",
    "    loss=loss, \n",
    "    input_shape=X_test[0].shape, \n",
    "    nb_classes=10,\n",
    "    device_type='cpu'\n",
    ")\n",
    "attack_model = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    eps=16 / 255 * 784**0.5,\n",
    "    norm=2,\n",
    ")\n",
    "\n",
    "base_k = 512\n",
    "idxs_chosen = random.sample(range(len(X_test)), k=base_k)\n",
    "x_original: np.ndarray = (X_test[idxs_chosen]).numpy()\n",
    "y_original: np.ndarray = (y_test[idxs_chosen]).numpy()\n",
    "\n",
    "x_adv = attack_model.generate(x_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b182fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels:  [4 4 0 2 0 6 5 7 3 3 3 3 1 3 3 1 3 5 7 1 3 5 4 8 7 1 7 9 7 2 2 2 6 9 7 7 6\n",
      " 3 9 7 5 2 6 0 9 3 0 4 4 9 2 1 9 2 4 4 6 2 9 8 2 9 0 4 8 3 8 5 7 2 8 2 9 8\n",
      " 5 9 2 2 5 7 0 4 1 7 4 6 7 5 4 6 6 5 9 1 0 7 3 4 9 7 5 3 1 3 2 6 1 5 8 9 5\n",
      " 3 2 2 5 4 1 1 5 1 4 5 2 4 7 7 2 9 2 3 0 4 1 3 7 2 2 7 5 1 6 5 1 9 0 5 5 2\n",
      " 6 9 0 9 1 5 5 3 0 4 1 6 9 4 3 7 6 4 3 4 9 3 1 9 7 1 8 3 1 1 0 7 6 3 9 1 1\n",
      " 8 1 2 7 7 3 0 0 0 1 1 1 7 7 9 3 4 3 8 9 1 3 2 1 3 0 1 7 9 2 2 4 1 7 3 0 3\n",
      " 6 9 2 8 5 9 2 1 0 7 5 1 1 1 5 3 9 2 9 5 6 1 9 7 0 4 9 1 4 0 5 6 1 8 5 8 6\n",
      " 3 3 2 8 8 4 0 3 6 8 3 1 9 6 9 7 5 1 6 2 4 7 8 1 4 9 6 9 8 4 7 2 6 9 0 6 8\n",
      " 4 8 9 0 0 1 9 1 9 9 1 7 8 9 2 1 6 0 4 7 9 8 3 2 2 9 1 1 0 6 5 4 8 9 6 4 8\n",
      " 5 8 4 6 5 7 2 6 8 1 6 1 2 8 6 4 2 7 5 5 5 0 6 3 2 9 8 3 4 6 3 4 3 4 0 6 7\n",
      " 6 4 3 7 9 0 5 1 1 9 1 8 0 5 5 7 3 8 0 6 1 8 6 4 4 7 3 2 5 3 0 0 2 1 1 5 7\n",
      " 2 9 0 1 8 2 1 2 9 6 6 8 9 9 9 5 1 0 4 2 2 2 1 9 1 9 8 7 9 6 9 1 4 7 9 4 2\n",
      " 3 0 0 3 6 6 8 0 6 1 2 0 5 3 4 4 4 0 0 8 3 4 5 5 5 5 5 4 5 5 9 5 2 7 2 6 4\n",
      " 7 8 0 9 4 6 9 2 1 4 4 8 2 9 0 1 1 6 5 7 0 0 2 5 0 3 9 4 6 6 6]\n",
      "Original predictions:  [4 4 0 2 0 6 5 7 3 3 3 3 1 3 3 1 3 5 7 1 3 5 4 8 7 1 7 9 7 2 2 2 6 9 7 7 6\n",
      " 3 9 7 5 7 6 0 9 3 0 4 4 9 2 1 9 2 4 4 6 2 9 8 2 9 0 4 8 3 8 5 3 2 8 2 9 8\n",
      " 5 9 2 2 5 7 0 4 1 7 4 6 7 5 4 6 6 5 9 1 0 7 3 4 9 7 5 3 1 3 2 6 1 5 8 9 5\n",
      " 3 2 2 5 4 1 1 5 1 4 5 2 4 7 7 2 9 2 3 0 9 1 3 7 2 2 2 5 1 6 5 1 9 0 5 5 2\n",
      " 6 9 0 9 1 5 5 3 0 4 1 6 9 4 3 7 6 4 3 4 9 3 1 9 7 1 8 3 1 1 0 7 6 3 9 1 1\n",
      " 8 1 2 7 7 3 0 0 0 1 1 1 7 7 9 3 4 3 8 9 1 3 2 1 3 0 1 7 9 2 2 4 1 7 3 0 3\n",
      " 6 9 2 8 5 9 2 1 0 7 5 1 1 1 5 3 9 2 9 5 6 1 9 7 0 4 9 1 4 0 5 6 1 8 5 8 6\n",
      " 3 3 2 8 8 4 0 3 6 8 3 1 9 6 9 7 5 1 6 2 4 7 8 1 4 9 6 9 8 4 7 2 6 9 0 6 8\n",
      " 4 8 9 0 0 1 9 1 9 9 1 7 8 9 2 1 6 0 4 7 9 8 3 2 2 9 1 1 0 6 5 4 8 9 6 4 8\n",
      " 5 8 4 6 5 7 2 6 8 1 6 1 2 8 6 4 2 7 5 5 5 0 6 3 2 9 8 3 4 6 3 4 3 4 0 6 7\n",
      " 6 4 3 7 9 0 5 1 1 9 1 8 0 5 5 7 3 8 0 6 1 8 6 4 4 7 3 2 5 3 0 0 2 1 1 5 7\n",
      " 2 9 0 1 8 2 1 2 9 6 6 8 9 9 7 5 1 0 4 2 2 2 1 9 1 9 8 7 9 6 9 1 4 7 9 4 2\n",
      " 3 0 0 3 6 6 8 0 6 1 2 0 5 3 4 4 4 0 0 8 3 4 5 5 5 5 5 4 5 5 9 5 2 7 2 6 4\n",
      " 7 8 0 9 4 6 9 2 1 4 4 8 2 9 0 1 1 6 5 7 0 0 2 5 0 3 9 4 6 6 6]\n",
      "Adversarial predictions (Projected Gradient Descent):  [4 4 0 2 0 6 5 8 3 3 3 3 1 3 3 1 3 5 7 1 3 5 1 8 7 1 7 4 7 2 2 2 2 9 7 7 6\n",
      " 3 9 7 5 2 6 0 9 3 0 4 8 9 2 1 9 2 4 4 6 2 9 8 2 9 0 4 8 3 8 5 7 2 8 2 9 8\n",
      " 3 9 2 2 6 7 0 4 1 7 4 6 7 5 4 4 6 5 9 1 0 7 3 4 9 7 5 3 1 7 2 6 1 5 8 9 1\n",
      " 3 2 2 5 4 1 1 5 1 4 3 2 4 7 7 2 4 2 3 0 4 1 3 7 2 2 7 5 1 6 5 1 9 0 5 5 2\n",
      " 6 8 0 9 1 5 5 3 0 9 1 5 9 4 3 7 6 4 3 4 9 3 1 8 7 1 8 3 1 1 0 7 4 3 9 1 1\n",
      " 8 1 2 7 7 3 0 0 0 1 1 1 7 7 4 3 4 3 8 9 1 3 2 1 3 0 1 7 9 2 2 4 1 7 3 0 3\n",
      " 6 9 2 8 5 9 2 1 0 7 5 1 1 1 3 3 8 2 9 5 6 1 9 7 0 4 4 1 4 0 5 6 1 8 5 8 6\n",
      " 3 3 2 8 8 4 0 3 6 8 3 1 9 0 9 7 5 1 6 2 4 7 8 1 4 4 6 9 8 4 9 2 6 9 0 6 8\n",
      " 4 8 9 0 0 1 9 1 9 9 1 3 8 8 2 1 6 6 4 7 9 8 3 2 2 9 1 1 0 6 5 4 8 9 6 4 8\n",
      " 5 8 4 6 5 7 2 6 8 1 6 1 2 8 6 4 2 7 5 5 5 0 6 3 2 9 8 3 4 4 3 4 3 4 0 6 7\n",
      " 6 4 3 7 8 0 5 1 1 8 1 8 0 5 5 7 3 8 0 6 1 8 6 4 4 7 3 2 5 3 0 4 2 1 1 5 7\n",
      " 2 9 0 1 8 2 1 2 4 6 6 2 9 9 0 5 1 0 4 1 2 2 1 9 1 9 8 7 9 6 9 1 4 7 8 4 6\n",
      " 3 0 0 3 6 6 8 0 6 1 2 0 5 3 4 4 6 0 6 8 3 4 5 5 3 5 8 4 5 5 8 5 2 7 2 6 4\n",
      " 7 8 0 5 4 6 9 2 1 4 4 8 2 7 0 1 1 2 5 7 0 0 2 6 0 3 8 4 6 6 6]\n",
      "Accuracy on adversarial examples: 90.82% (465/512)\n",
      "Effectiveness of attack (1-accuracy): 9.18% \n"
     ]
    }
   ],
   "source": [
    "y_adv: np.ndarray = torch.argmax(\n",
    "    model(torch.from_numpy(x_adv)), dim=1\n",
    ").numpy()\n",
    "\n",
    "print(\"Original labels: \", y_original)\n",
    "print(\"Original predictions: \", torch.argmax(model(torch.from_numpy(x_original)), dim=1).numpy())\n",
    "print(\"Adversarial predictions (Projected Gradient Descent): \", y_adv)\n",
    "\n",
    "adv_well_classified = x_adv[y_adv == y_original]\n",
    "accuracy = (y_adv == y_original).sum().item() / len(y_original)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy*100:.2f}% ({len(adv_well_classified)}/{base_k})\")\n",
    "print(f\"Effectiveness of attack (1-accuracy): {(1 - accuracy)*100:.2f}% \")\n",
    "\n",
    "# Now Cho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc7efe",
   "metadata": {},
   "source": [
    "Now from the successfuly images that got attacked, choose 10 examples\n",
    "and from the original dataset choose 10 TP and 10 wrongly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 47 successful adversarial examples\n"
     ]
    }
   ],
   "source": [
    "successful_adv_examples = x_adv[y_adv != y_original]\n",
    "well_classified = x_original[y_adv == y_original]\n",
    "wrongly_classified: np.ndarray = X_test[pred != y_test].numpy()\n",
    "\n",
    "print(f\"Got {len(successful_adv_examples)} successful adversarial examples\")\n",
    "\n",
    "chosen_adv_examples_idxs = random.sample(range(len(successful_adv_examples)), k=NUM_EXAMPLES)\n",
    "chosen_well_classified_idxs = random.sample(range(len(well_classified)), k=NUM_EXAMPLES)\n",
    "chosen_wrongly_classified_idxs = random.sample(range(len(wrongly_classified)), k=NUM_EXAMPLES)\n",
    "\n",
    "final_dataset = {\n",
    "    \"adv_examples\": {\n",
    "        \"x\": successful_adv_examples[chosen_adv_examples_idxs], \n",
    "        \"y\": y_adv[chosen_adv_examples_idxs]\n",
    "    },\n",
    "    \"original_adv_example\": {\n",
    "        \"x\": x_original[chosen_adv_examples_idxs], \n",
    "        \"y\": y_original[chosen_adv_examples_idxs]\n",
    "    },\n",
    "    \"well_classified\": {\n",
    "        \"x\": well_classified[chosen_well_classified_idxs], \n",
    "        \"y\": y_original[chosen_well_classified_idxs]\n",
    "    },\n",
    "    \"wrongly_classified\": {\n",
    "        \"x\": wrongly_classified[chosen_wrongly_classified_idxs],\n",
    "        \"y\": y_test[chosen_wrongly_classified_idxs].numpy()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad93424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(final_dataset, open(\"metric_testing_dataset.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
