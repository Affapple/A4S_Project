{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e97372",
   "metadata": {},
   "source": [
    "# Test dataset\n",
    "\n",
    "## MNIST Dataset\n",
    "\n",
    "In this file, we aim to get 4 sets of examples to test our metric from the MNIST dataset:\n",
    "- Well-classified examples\n",
    "- Wrongly classified examples\n",
    "- Adversarial examples (well classified examples modified to be wrongly classified)\n",
    "- Original examples of the adversarial examples before attack\n",
    "\n",
    "## Income Dataset\n",
    "For the Income NN, we also aim to prepare the same 4 datasets, but with example images extracted from online sources. However we won't prepare 4 datasets with 10 examples each as finding images that were wrongly classified would be a lengthy process\n",
    "\n",
    "\n",
    "By running this file you should get a file called `metric_testing_dataset.pkl` and a file called `income_metric_testing_dataset.pkl`, which is a pickle file of a dictionary `dict[str, np.ndarray]`, with the examples to be used to test the metric.\\\n",
    "These files should be copied into `./tests/data/metric_testing_dataset.pkl` and `./tests/data/income_metric_testing_dataset.pkl` to be used for testing in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61182894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Num of examples to save for each set\n",
    "NUM_EXAMPLES = 10\n",
    "INCOME_MODEL_PATH = \"income_model.pt\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "from model import MNIST_Model, IncomeModel, get_mnist_dataset, load_cnn_model\n",
    "\n",
    "# Helper to stop execution in notebook\n",
    "def exit():\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            return []\n",
    "    raise StopExecution\n",
    "device = torch.device(\"cpu\") # Keep CPU to not deal with space constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d715e",
   "metadata": {},
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c786066",
   "metadata": {},
   "outputs": [],
   "source": [
    "model: MNIST_Model = load_cnn_model()\n",
    "if model is None:\n",
    "    print(\"Could not load model, something went wrong\")\n",
    "    exit()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, test_dataset = get_mnist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad081581",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=len(test_dataset),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c716b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2120c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 99.04% (9904/10000)\n"
     ]
    }
   ],
   "source": [
    "# Classify test dataset\n",
    "pred = model.forward(X_test)\n",
    "pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "well_classified = y_test[pred == y_test]\n",
    "\n",
    "accuracy = (pred == y_test).sum().item() / len(y_test)\n",
    "print(f\"Accuracy on test dataset: {accuracy*100:.2f}% ({len(well_classified)}/{len(y_test)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfa0f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model, \n",
    "    loss=loss, \n",
    "    input_shape=X_test[0].shape, \n",
    "    nb_classes=10,\n",
    "    device_type='cpu'\n",
    ")\n",
    "attack_model = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    eps=16 / 255 * 784**0.5,\n",
    "    norm=2,\n",
    ")\n",
    "\n",
    "base_k = 512\n",
    "idxs_chosen = random.sample(range(len(X_test)), k=base_k)\n",
    "x_original: np.ndarray = (X_test[idxs_chosen]).numpy()\n",
    "y_original: np.ndarray = (y_test[idxs_chosen]).numpy()\n",
    "\n",
    "x_adv = attack_model.generate(x_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b182fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial examples: 90.82% (465/512)\n",
      "Effectiveness of attack (1-accuracy): 9.18% \n"
     ]
    }
   ],
   "source": [
    "y_adv: np.ndarray = torch.argmax(\n",
    "    model(torch.from_numpy(x_adv)), dim=1\n",
    ").numpy()\n",
    "\n",
    "adv_well_classified = x_adv[y_adv == y_original]\n",
    "accuracy = (y_adv == y_original).sum().item() / len(y_original)\n",
    "print(f\"Accuracy on adversarial examples: {accuracy*100:.2f}% ({len(adv_well_classified)}/{base_k})\")\n",
    "print(f\"Effectiveness of attack (1-accuracy): {(1 - accuracy)*100:.2f}% \")\n",
    "\n",
    "# Now Cho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc7efe",
   "metadata": {},
   "source": [
    "Now from the successfuly images that got attacked, choose 10 examples\n",
    "and from the original dataset choose 10 TP and 10 wrongly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd0f5395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 47 successful adversarial examples\n"
     ]
    }
   ],
   "source": [
    "successful_adv_examples = x_adv[y_adv != y_original]\n",
    "well_classified = x_original[y_adv == y_original]\n",
    "wrongly_classified: np.ndarray = X_test[pred != y_test].numpy()\n",
    "\n",
    "print(f\"Got {len(successful_adv_examples)} successful adversarial examples\")\n",
    "\n",
    "chosen_adv_examples_idxs = random.sample(range(len(successful_adv_examples)), k=NUM_EXAMPLES)\n",
    "chosen_well_classified_idxs = random.sample(range(len(well_classified)), k=NUM_EXAMPLES)\n",
    "chosen_wrongly_classified_idxs = random.sample(range(len(wrongly_classified)), k=NUM_EXAMPLES)\n",
    "\n",
    "final_dataset = {\n",
    "    \"adv_examples\": {\n",
    "        \"x\": successful_adv_examples[chosen_adv_examples_idxs], \n",
    "        \"y\": y_adv[chosen_adv_examples_idxs]\n",
    "    },\n",
    "    \"original_adv_example\": {\n",
    "        \"x\": x_original[chosen_adv_examples_idxs], \n",
    "        \"y\": y_original[chosen_adv_examples_idxs]\n",
    "    },\n",
    "    \"well_classified\": {\n",
    "        \"x\": well_classified[chosen_well_classified_idxs], \n",
    "        \"y\": y_original[chosen_well_classified_idxs]\n",
    "    },\n",
    "    \"wrongly_classified\": {\n",
    "        \"x\": wrongly_classified[chosen_wrongly_classified_idxs],\n",
    "        \"y\": y_test[chosen_wrongly_classified_idxs].numpy()\n",
    "    }\n",
    "}\n",
    "import pickle\n",
    "pickle.dump(final_dataset, open(\"metric_testing_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedcbe80",
   "metadata": {},
   "source": [
    "# Income Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bca39e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "data = pd.read_csv(r'./data/income/adult.csv')\n",
    "col_names = data.columns\n",
    "num_rows = data.shape[0]\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)  # reshuffle dataset and drop new column of index labelling that is made\n",
    "\n",
    "categorical_features = ['workclass', 'education', 'marital.status', 'occupation', \n",
    "                        'relationship', 'race', 'sex', 'native.country', 'income']\n",
    "for feature in categorical_features:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data[feature] = label_encoder.fit_transform(data[feature])\n",
    "\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "538b46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 successful adversarial examples and their originals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "continuous_features = ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "scaler = StandardScaler()\n",
    "X[continuous_features] = scaler.fit_transform(X[continuous_features])\n",
    "\n",
    "# Prepare tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Load model\n",
    "input_dim = X_tensor.shape[1]\n",
    "model = torch.jit.load(INCOME_MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(X_tensor)\n",
    "    pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "# Strictly select well-classified and wrongly-classified indices\n",
    "well_mask = (pred == y_tensor)\n",
    "wrong_mask = (pred != y_tensor)\n",
    "well_idxs = torch.where(well_mask)[0].numpy()\n",
    "wrong_idxs = torch.where(wrong_mask)[0].numpy()\n",
    "\n",
    "NUM_EXAMPLES = 10\n",
    "chosen_well_idxs = np.random.choice(well_idxs, min(NUM_EXAMPLES, len(well_idxs)), replace=False)\n",
    "chosen_wrong_idxs = np.random.choice(wrong_idxs, min(NUM_EXAMPLES, len(wrong_idxs)), replace=False)\n",
    "\n",
    "# Select a batch of well-classified examples to attack\n",
    "base_k = 128\n",
    "if len(well_idxs) < base_k:\n",
    "    base_k = len(well_idxs)\n",
    "attack_idxs = np.random.choice(well_idxs, base_k, replace=False)\n",
    "x_original = X_tensor[attack_idxs].numpy()\n",
    "y_original = y_tensor[attack_idxs].numpy()\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=loss,\n",
    "    input_shape=X_tensor[0].shape,\n",
    "    nb_classes=2,\n",
    "    device_type='cpu'\n",
    ")\n",
    "attack_model = ProjectedGradientDescent(\n",
    "    estimator=classifier,\n",
    "    eps=0.2,  # You may tune this value\n",
    "    norm=np.inf,\n",
    ")\n",
    "\n",
    "x_adv = attack_model.generate(x_original)\n",
    "y_adv = np.argmax(model(torch.from_numpy(x_adv)).detach().numpy(), axis=1)\n",
    "\n",
    "# Only keep successful adversarial examples (where prediction changed)\n",
    "success_mask = (y_adv != y_original)\n",
    "successful_adv = x_adv[success_mask]\n",
    "successful_orig = x_original[success_mask]\n",
    "successful_y_adv = y_adv[success_mask]\n",
    "successful_y_orig = y_original[success_mask]\n",
    "\n",
    "chosen_adv_idxs = np.random.choice(np.arange(len(successful_adv)), min(NUM_EXAMPLES, len(successful_adv)), replace=False)\n",
    "\n",
    "final_income_dataset = {\n",
    "    \"well_classified\": {\n",
    "        \"x\": X_tensor[chosen_well_idxs].numpy(),\n",
    "        \"y\": y_tensor[chosen_well_idxs].numpy()\n",
    "    },\n",
    "    \"wrongly_classified\": {\n",
    "        \"x\": X_tensor[chosen_wrong_idxs].numpy(),\n",
    "        \"y\": y_tensor[chosen_wrong_idxs].numpy()\n",
    "    },\n",
    "    \"adv_examples\": {\n",
    "        \"x\": successful_adv[chosen_adv_idxs],\n",
    "        \"y\": successful_y_adv[chosen_adv_idxs]\n",
    "    },\n",
    "    \"original_adv_example\": {\n",
    "        \"x\": successful_orig[chosen_adv_idxs],\n",
    "        \"y\": successful_y_orig[chosen_adv_idxs]\n",
    "    }\n",
    "}\n",
    "import pickle\n",
    "pickle.dump(final_income_dataset, open(\"income_metric_testing_dataset.pkl\", \"wb\"))\n",
    "print(f\"Saved {len(chosen_adv_idxs)} successful adversarial examples and their originals.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bdeffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check accuracies and diagnostics:\n",
      "\n",
      "Set: well_classified\n",
      "  Shape x: (10, 14), y: (10,)\n",
      "  Pred: [0 0 0 0 1 1 1 0 0 0]\n",
      "  True: [0 0 0 0 1 1 1 0 0 0]\n",
      "  Match: [ True  True  True  True  True  True  True  True  True  True]\n",
      "  First 5 x: [[-5.6672013e-01  2.0000000e+00 -3.4881806e-01  1.5000000e+01\n",
      "  -4.8076451e-02  2.0000000e+00  2.0000000e+00  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "  -7.8031331e-02  3.8000000e+01]\n",
      " [-7.9518348e-01  2.0000000e+00 -1.2143841e+00  1.1000000e+01\n",
      "  -4.4043392e-01  4.0000000e+00  9.0000000e+00  4.0000000e+00\n",
      "   2.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "  -7.8031331e-02  3.8000000e+01]\n",
      " [-1.0998013e+00  2.0000000e+00 -1.1137565e+00  9.0000000e+00\n",
      "   1.1289960e+00  4.0000000e+00  0.0000000e+00  3.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00  1.4970450e-01 -2.1867335e-01\n",
      "  -9.1285658e-01  3.8000000e+01]\n",
      " [-4.1441122e-01  2.0000000e+00 -1.0733102e-02  1.1000000e+01\n",
      "  -4.4043392e-01  2.0000000e+00  2.0000000e+00  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "   7.5679392e-01  3.8000000e+01]\n",
      " [ 1.0325234e+00  3.0000000e+00 -8.4508491e-01  1.5000000e+01\n",
      "  -4.8076451e-02  2.0000000e+00  1.1000000e+01  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00  1.8803053e+00 -2.1867335e-01\n",
      "   7.5679392e-01  3.8000000e+01]]\n",
      "  First 5 y: [0 0 0 0 1]\n",
      "  Accuracy on well_classified: 1.0\n",
      "\n",
      "Set: wrongly_classified\n",
      "  Shape x: (10, 14), y: (10,)\n",
      "  Pred: [0 1 0 0 1 1 0 0 1 1]\n",
      "  True: [1 0 1 1 0 0 1 1 0 0]\n",
      "  Match: [False False False False False False False False False False]\n",
      "  First 5 x: [[ 1.2609868e+00  2.0000000e+00  3.3873558e-02  1.5000000e+01\n",
      "  -4.8076451e-02  2.0000000e+00  1.2000000e+01  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "  -7.8031331e-02  3.8000000e+01]\n",
      " [ 4.2515505e-02  2.0000000e+00  8.4009653e-01  8.0000000e+00\n",
      "   3.4428102e-01  2.0000000e+00  2.0000000e+00  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01  3.8066602e+00\n",
      "   5.8982891e-01  3.8000000e+01]\n",
      " [-1.8594787e-01  2.0000000e+00 -7.3159486e-01  6.0000000e+00\n",
      "  -2.0098639e+00  2.0000000e+00  1.1000000e+01  3.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "   7.5679392e-01  3.8000000e+01]\n",
      " [ 9.5636898e-01  2.0000000e+00 -5.3436208e-01  1.1000000e+01\n",
      "  -4.4043392e-01  2.0000000e+00  1.2000000e+01  0.0000000e+00\n",
      "   4.0000000e+00  1.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "  -7.8031331e-02  3.8000000e+01]\n",
      " [-8.7133795e-01  5.0000000e+00  3.4420664e+00  9.0000000e+00\n",
      "   1.1289960e+00  2.0000000e+00  1.0000000e+01  5.0000000e+00\n",
      "   2.0000000e+00  0.0000000e+00 -1.4750209e-01 -2.1867335e-01\n",
      "   5.8982891e-01  3.8000000e+01]]\n",
      "  First 5 y: [1 0 1 1 0]\n",
      "  Accuracy on wrongly_classified: 0.0\n",
      "\n",
      "Set: adv_examples\n",
      "  Shape x: (10, 14), y: (10,)\n",
      "  Pred: [1 0 1 0 1 0 0 0 1 1]\n",
      "  True: [1 0 1 0 1 0 0 0 1 1]\n",
      "  Match: [ True  True  True  True  True  True  True  True  True  True]\n",
      "  First 5 x: [[ 1.1563690e+00  1.8000000e+00 -6.2310809e-01  7.8000002e+00\n",
      "   5.4428101e-01  1.8000000e+00  4.8000002e+00 -2.0000000e-01\n",
      "   3.8000000e+00  1.2000000e+00  5.2497908e-02 -1.8673345e-02\n",
      "   1.2196867e-01  1.1200000e+01]\n",
      " [-1.5748450e-01  2.2000000e+00 -6.8064100e-01  8.8000002e+00\n",
      "   9.2899603e-01  2.2000000e+00 -2.0000000e-01  2.0000000e-01\n",
      "   8.0000001e-01  8.0000001e-01 -3.4750211e-01 -4.1867334e-01\n",
      "  -2.7803135e-01  2.8799999e+01]\n",
      " [-2.9056567e-01  1.8000000e+00  8.8483924e-01  1.0800000e+01\n",
      "  -2.4043392e-01  1.8000000e+00  5.8000002e+00 -2.0000000e-01\n",
      "   4.1999998e+00  1.2000000e+00  5.2497908e-02 -1.8673345e-02\n",
      "   1.2196867e-01  3.8000000e+01]\n",
      " [ 1.4713334e-01  3.2000000e+00 -1.1935239e-01  9.1999998e+00\n",
      "   9.2899603e-01  2.2000000e+00  2.8000000e+00  2.0000000e-01\n",
      "   4.1999998e+00  8.0000001e-01 -3.4750211e-01 -4.1867334e-01\n",
      "   5.5679393e-01  3.7799999e+01]\n",
      " [ 9.2790562e-01  1.8000000e+00 -1.2539331e+00  1.0800000e+01\n",
      "  -2.4043392e-01  1.8000000e+00  2.2000000e+00 -2.0000000e-01\n",
      "   3.8000000e+00  1.2000000e+00  5.2497908e-02 -1.8673345e-02\n",
      "   5.3938133e-01  3.8200001e+01]]\n",
      "  First 5 y: [1 0 1 0 1]\n",
      "  Accuracy on adv_examples: 1.0\n",
      "\n",
      "Set: original_adv_example\n",
      "  Shape x: (10, 14), y: (10,)\n",
      "  Pred: [0 1 0 1 0 1 1 1 0 0]\n",
      "  True: [0 1 0 1 0 1 1 1 0 0]\n",
      "  Match: [ True  True  True  True  True  True  True  True  True  True]\n",
      "  First 5 x: [[ 0.956369    2.         -0.8231081   8.          0.34428102  2.\n",
      "   5.          0.          4.          1.         -0.1475021  -0.21867335\n",
      "  -0.07803133 11.        ]\n",
      " [ 0.04251551  2.         -0.480641    9.          1.128996    2.\n",
      "   0.          0.          1.          1.         -0.1475021  -0.21867335\n",
      "  -0.07803133 29.        ]\n",
      " [-0.4905657   2.          0.68483925 11.         -0.44043392  2.\n",
      "   6.          0.          4.          1.         -0.1475021  -0.21867335\n",
      "  -0.07803133 38.        ]\n",
      " [ 0.34713334  3.          0.08064761  9.          1.128996    2.\n",
      "   3.          0.          4.          1.         -0.1475021  -0.21867335\n",
      "   0.7567939  38.        ]\n",
      " [ 0.72790563  2.         -1.4539331  11.         -0.44043392  2.\n",
      "   2.          0.          4.          1.         -0.1475021  -0.21867335\n",
      "   0.3393813  38.        ]]\n",
      "  First 5 y: [0 1 0 1 0]\n",
      "  Accuracy on original_adv_example: 1.0\n",
      "\n",
      "Checking alignment between adv_examples and original_adv_example:\n",
      "  Mean L1 diff per example: 2.7300\n",
      "  First 5 diffs: [2.7999997 2.800001  2.5999997 2.8000007 2.800001 ]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: accuracy on each set, plus diagnostics\n",
    "model.eval()\n",
    "def accuracy_on_set(model, x, y, set_name=None):\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.from_numpy(x))\n",
    "        pred = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        y_true = y\n",
    "        acc = (pred == y_true)\n",
    "        if set_name:\n",
    "            print(f\"\\nSet: {set_name}\")\n",
    "        print(f\"  Shape x: {x.shape}, y: {y.shape}\")\n",
    "        print(f\"  Pred: {pred}\")\n",
    "        print(f\"  True: {y_true}\")\n",
    "        print(f\"  Match: {pred == y_true}\")\n",
    "        print(f\"  First 5 x: {x[:5]}\")\n",
    "        print(f\"  First 5 y: {y_true[:5]}\")\n",
    "        return acc.mean()\n",
    "\n",
    "print(\"Sanity check accuracies and diagnostics:\")\n",
    "for key in [\"well_classified\", \"wrongly_classified\", \"adv_examples\", \"original_adv_example\"]:\n",
    "    x = final_income_dataset[key]['x']\n",
    "    y = final_income_dataset[key]['y']\n",
    "    acc = accuracy_on_set(model, x, y, set_name=key)\n",
    "    print(f\"  Accuracy on {key}: {acc}\")\n",
    "\n",
    "# Check alignment between adv_examples and original_adv_example\n",
    "print(\"\\nChecking alignment between adv_examples and original_adv_example:\")\n",
    "adv_x = final_income_dataset['adv_examples']['x']\n",
    "orig_x = final_income_dataset['original_adv_example']['x']\n",
    "if adv_x.shape == orig_x.shape:\n",
    "    diffs = np.abs(adv_x - orig_x).sum(axis=1)\n",
    "    print(f\"  Mean L1 diff per example: {diffs.mean():.4f}\")\n",
    "    print(f\"  First 5 diffs: {diffs[:5]}\")\n",
    "else:\n",
    "    print(f\"  Shape mismatch: adv_x {adv_x.shape}, orig_x {orig_x.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
